{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bcb12460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def search_paper(domain: str, limit: int = 3):\n",
    "    \"\"\"Fetches latest or specific papers from arXiv for the given domain.\n",
    "\n",
    "    Args:\n",
    "        domain (str): _description_\n",
    "        limit (int, optional): _description_. Defaults to 3.\n",
    "        \n",
    "    Returns:\n",
    "        List of papers that successfully fetched\n",
    "    \"\"\"\n",
    "    \n",
    "    # if limit > settings.MAXIMUM_PAPER:\n",
    "    #     return f\"Limit to {settings.MAXIMUM_PAPER} papers for each request\"\n",
    "    \n",
    "    url = f\"https://arxiv.org/search/?query={domain}&searchtype=all&abstracts=show&order=-announced_date_first&size=50\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    results = []\n",
    "    papers = soup.find_all(\"li\", class_=\"arxiv-result\")[:limit]\n",
    "\n",
    "    for paper in papers:\n",
    "        title = paper.find(\"p\", class_=\"title\").text.strip()\n",
    "        authors = paper.find(\"p\", class_=\"authors\").text.strip().replace(\"Authors:\", \"\").strip()\n",
    "        abstract = paper.find(\"span\", class_=\"abstract-full\").text.strip().replace(\"\\n\", \" \")\n",
    "        source_url = paper.find(\"p\", class_=\"list-title\").find(\"a\")[\"href\"]\n",
    "        pdf_url = paper.find(\"p\", class_=\"list-title\").find(\"span\").find(\"a\")[\"href\"]\n",
    "\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"abstract\": abstract,\n",
    "            \"source_url\": source_url,\n",
    "            \"pdf_url\": pdf_url\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c354249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_url': 'https://arxiv.org/abs/2512.19683',\n",
       "  'pdf_url': 'https://arxiv.org/pdf/2512.19683'},\n",
       " {'source_url': 'https://arxiv.org/abs/2512.19644',\n",
       "  'pdf_url': 'https://arxiv.org/pdf/2512.19644'},\n",
       " {'source_url': 'https://arxiv.org/abs/2512.19632',\n",
       "  'pdf_url': 'https://arxiv.org/pdf/2512.19632'}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_links = [\n",
    "    {\n",
    "        \"source_url\": l[\"source_url\"].strip(),\n",
    "        \"pdf_url\": l[\"pdf_url\"].strip(),\n",
    "    } \n",
    "    for l in search_paper(\"AI\")\n",
    "]\n",
    "pdf_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59d852e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def review_paper(pdf_urls: str, source_urls: str):\n",
    "    \"\"\"Fetch string of urls divided by comma e.g: url1, url2, url3\n",
    "\n",
    "    Args:\n",
    "        pdf_urls (str): list of string of PDF URLs\n",
    "        source_urls (str): list of string of source URLs\n",
    "    \"\"\"\n",
    "        \n",
    "    try:\n",
    "        pdf_urls = [i.strip() for i in pdf_urls.split(\",\")]\n",
    "        source_urls = [i.strip() for i in source_urls.split(\",\")]\n",
    "    except:\n",
    "        return \"Unable to process the urls\"\n",
    "    \n",
    "    pdfs: list[PdfReader] = []\n",
    "    for i, url in enumerate(pdf_urls):\n",
    "        response = requests.get(url)\n",
    "        status_code = response.status_code\n",
    "        \n",
    "        if status_code != 200:\n",
    "            pdfs.append(f\"PDF Unavailable | Take a look at {source_urls[i]}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            file_object = io.BytesIO(response.content)\n",
    "            reader = PdfReader(file_object)\n",
    "            pdfs.append(reader.metadata)\n",
    "        except:\n",
    "            pdfs.append(f\"Unable to process the PDF | take a look at {source_urls[i]}\")\n",
    "        \n",
    "    return pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a024a462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PDF Unavailable | Take a look at https://arxiv.org/abs/2512.19683',\n",
       " 'PDF Unavailable | Take a look at https://arxiv.org/abs/2512.19644',\n",
       " {'/Author': 'Da Tan; Michael Beck; Christopher P. Bidinosti; Robert H. Gulden; Christopher J. Henry',\n",
       "  '/Creator': 'arXiv GenPDF (tex2pdf:57610bf)',\n",
       "  '/DOI': 'https://doi.org/10.48550/arXiv.2512.19632',\n",
       "  '/License': 'http://creativecommons.org/licenses/by/4.0/',\n",
       "  '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1',\n",
       "  '/Producer': 'pikepdf 8.15.1',\n",
       "  '/Title': 'Generative diffusion models for agricultural AI: plant image generation, indoor-to-outdoor translation, and expert preference alignment',\n",
       "  '/Trapped': '/False',\n",
       "  '/arXivID': 'https://arxiv.org/abs/2512.19632v1'}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_paper(\n",
    "    \",\".join(i[\"pdf_url\"] for i in pdf_links), \n",
    "    \",\".join(i[\"source_url\"] for i in pdf_links)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch280",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
